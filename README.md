# Machine_Learning
## All Machine Projects:

## "Capstone Project": 
Built a stock price predictor - This work involved research in financial data analysis as well as trying out various machine learning techniques such as Polynomial learn Regression, KNN, ARIMA for predicting stock prices. Finally, I have used Linear Regression to predict stock prices one day ,7 days, 14 days, 28 days in future with ‘>=.85’ R-squared score on the test datasets

-------------------------------------------------------------------------------------------------------------------

## "Boston-housing": 
Predicting Boston Housing Prices - Evaluated the performance and predictive power of a model that has been trained and tested on data collected from homes in suburbs of Boston, Massachusetts. This could be invaluable for someone like a real estate agent who could make use of such information daily.

•	Constructed a model that could accurately predict the value of a given house in the Boston real estate market using various statistical analysis tools.
•	Analysed the UCI ML Repository Housing data using Decision Tree Regressor and used it to identify the best price that a client can sell their house.

-------------------------------------------------------------------------------------------------------------------

## "Creating_customer_segments": 
Created Customer Segments with Unsupervised learning techniques - K means, Gaussian Mixture Model, Means Shift Clustering, Density Based clustering -  I have analyzed the dataset containing data on various customers' annual spending amounts (reported in monetary units) of diverse product categories for internal structure. One goal of this project is to best describe the variation in the different types of customers that a wholesale distributor interacts with. Doing so would equip the distributor with insight into how to best structure their delivery service to meet the needs of each customer.

Reviewed unstructured data to understand the patterns and natural categories that the data fits into. Used multiple algorithms and both empirically and theoretically compared and contrasted their results. Made predictions about the natural categories of multiple types in a dataset, then checked these predictions against the result of unsupervised analysis.

--------------------------------------------------------------------------------------------------------------------

## "Smartcab": 
Applied reinforcement learning to build a simulated vehicle navigation agent. This project involved modeling a complex control problem in terms of limited available inputs, and designing a scheme to automatically learn an optimal driving strategy based on rewards and penalties.
--------------------------------------------------------------------------------------------------------------------

## "Titanic_survival_exploration" - 
In 1912, the ship RMS Titanic struck an iceberg on its maiden voyage and sank, resulting in the deaths of most of its passengers and crew. In this project, I have explored a subset of the RMS Titanic passenger manifest to determine which features best predict whether someone survived or did not survive.

•	Constructed a model that could accurately predict the outcome of survival for passengers and crews utilizing machine learning.
•	Analysed the Kaggle data, trained and tested with Random Forest (96.63% accuracy), KNN (82,49% accuracy), Support Vector Machine (86.53% accuracy), Logistic Regression (80.58% accuracy) and Gaussian Naive Bayes (75.86% accuracy) to find the outcome of survival.


--------------------------------------------------------------------------------------------------------------------

## "Finding Donors for Charity in California" -

•	Constructed a model that could accurately predict whether an individual makes more than $50,000 per year, thus increasing the likelihood of donations.
•	Analysed UCI ML Repository Census data, trained and tested with AdaBoost (86.77% accuracy), Random Forest and Naive Bayes to find the highest amount of donation.

---------------------------------------------------------------------------------------------------------------------

